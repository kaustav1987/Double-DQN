{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Double DQN  Kaustav Implementation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1WUmtXjfDsj",
        "colab_type": "text"
      },
      "source": [
        "# Double Deep Q-Network (Double DQN)\n",
        "---\n",
        "In this notebook, you will implement a DQN agent with OpenAI Gym's LunarLander-v2 environment.\n",
        "\n",
        "### 1. Import the Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZT6doLTe75s",
        "colab_type": "code",
        "outputId": "0f6d5c0f-377e-4262-8e10-e7d145467823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 10.7 GB  | Proc size: 154.7 MB\n",
            "GPU RAM Free: 14304MB | Used: 775MB | Util   5% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymAnIyhQfJpv",
        "colab_type": "code",
        "outputId": "67a9368b-2d46-41de-aeef-0f221c1582de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "source": [
        "!apt-get install -y python-numpy python-dev cmake zlib1g-dev libjpeg-dev xvfb libav-tools xorg-dev python-opengl libboost-all-dev libsdl2-dev swig\n",
        "!pip install pyvirtualdisplay\n",
        "##!pip install piglet\n",
        "!pip install pyglet==1.3.2  ###DONT CHANGE THE VERSION\n",
        "!apt-get install xvfb\n",
        "from pyvirtualdisplay import Display\n",
        "!apt-get install cmake\n",
        "!pip install setuptool\n",
        "!pip install ez_setup\n",
        "!pip install gym[atari] "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package libav-tools is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "However the following packages replace it:\n",
            "  ffmpeg\n",
            "\n",
            "E: Package 'libav-tools' has no installation candidate\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.6/dist-packages (0.2.4)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.6/dist-packages (from pyvirtualdisplay) (0.2.7)\n",
            "Requirement already satisfied: pyglet==1.3.2 in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.3.2) (0.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.3).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.10.2-1ubuntu2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "Collecting setuptool\n",
            "\u001b[31m  ERROR: Could not find a version that satisfies the requirement setuptool (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for setuptool\u001b[0m\n",
            "Requirement already satisfied: ez_setup in /usr/local/lib/python3.6/dist-packages (0.9)\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.6/dist-packages (0.10.11)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.16.4)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.12.0)\n",
            "Requirement already satisfied: PyOpenGL; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (3.1.0)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (4.3.0)\n",
            "Requirement already satisfied: atari-py>=0.1.4; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (0.1.15)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym[atari]) (0.16.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (2019.6.16)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow; extra == \"atari\"->gym[atari]) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO_rmyb_f3Kh",
        "colab_type": "code",
        "outputId": "af739d00-9e25-4803-a964-a30fa671fcb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "!pip install box2d-py\n",
        "!pip install gym[Box_2D]\n",
        "import gym\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "!pip -m pip install pyvirtualdisplay\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "is_ipython = 'inline' in plt.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.6/dist-packages (2.3.8)\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.6/dist-packages (0.10.11)\n",
            "\u001b[33m  WARNING: gym 0.10.11 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.16.4)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (2.21.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.3.1)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[Box_2D]) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[Box_2D]) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[Box_2D]) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[Box_2D]) (2.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym[Box_2D]) (0.16.0)\n",
            "\n",
            "Usage:   \n",
            "  pip3 <command> [options]\n",
            "\n",
            "no such option: -m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So86pwYund1x",
        "colab_type": "text"
      },
      "source": [
        "Define Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI7LTn-Qncwc",
        "colab_type": "code",
        "outputId": "79c17dac-246d-4f53-b8a7-44d934ff6a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "env = gym.make('LunarLander-v2')\n",
        "env.seed(0)\n",
        "print('State shape: ', env.observation_space.shape)\n",
        "print('Number of actions: ', env.action_space.n)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "State shape:  (8,)\n",
            "Number of actions:  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt17L7o1k3X0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Network\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class QNetwork(nn.Module):\n",
        "  \"\"\"Actor (Policy) Model.\"\"\"\n",
        "  def __init__(self, state_size, action_size, seed,fc1_size =64, fc2_size=64):\n",
        "    '''\n",
        "    Initialize Parameters\n",
        "    '''\n",
        "    super(QNetwork, self).__init__()\n",
        "    self.state_size = state_size\n",
        "    self.action_size = action_size\n",
        "    self.seed = torch.manual_seed(seed)\n",
        "    self.FC1_size = fc1_size\n",
        "    self.FC2_size = fc2_size\n",
        "    self.FC1 = nn.Linear(self.state_size, self.FC1_size)\n",
        "    self.FC2 = nn.Linear(self.FC1_size, self.FC2_size)\n",
        "    self.FC3 = nn.Linear(self.FC2_size, self.action_size)\n",
        "    \n",
        "  \n",
        "  def forward(self, state):\n",
        "    \"\"\"\n",
        "    Build a network that maps state -> action values.\n",
        "    \"\"\"\n",
        "    x = F.relu(self.FC1(state))\n",
        "    x = F.relu(self.FC2(x))\n",
        "    x = self.FC3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS7fkQjAm6Mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import namedtuple, deque\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "##HYPERPARAMETERS\n",
        "\n",
        "BUFFER_SIZE = int(1e5)  ##replay buffer size\n",
        "BATCH_SIZE  = 128       ##minibatch size\n",
        "GAMMA  = .99            ##discount factor\n",
        "TAU = 1e-3              # for soft update of target parameters\n",
        "LR = 5e-4               # learning rate\n",
        "#LR = 1e-5  \n",
        "\n",
        "UPDATE_EVERY = 4        ## how often local network gets copied to target network\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MZPZoas1DF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Define the Replay Buffer ( Deque)\n",
        "\n",
        "class ReplayBuffer:\n",
        "  \"\"\"\n",
        "  Fixed-size buffer to store experience tuples.\n",
        "  \"\"\"\n",
        "  def __init__(self,action_size, buffer_size, batch_size, seed):\n",
        "    self.seed = random.seed(seed)\n",
        "    self.buffer_size = buffer_size\n",
        "    self.batch_size = batch_size\n",
        "    self.action_size = action_size\n",
        "    \n",
        "    \n",
        "    self.experience = namedtuple(\"Experience\", field_names =[\"state\", \"actions\",\"rewards\",\"next_state\", \"done\"])\n",
        "    self.memory = deque(maxlen= buffer_size)\n",
        "    \n",
        "  def add(self, state, action,rewards, next_state, done):\n",
        "      \n",
        "    experience = self.experience(state, action,rewards,next_state, done)\n",
        "    self.memory.append(experience)\n",
        "      \n",
        "  def sample(self):\n",
        "    '''\n",
        "    Randomly sample a batch from experience\n",
        "    '''\n",
        "      \n",
        "    experiences = random.sample(self.memory,k = self.batch_size)\n",
        "      \n",
        "    state = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "    actions = torch.from_numpy(np.vstack([e.actions for e in experiences if e is not None])).long().to(device)  ## dont change to float\n",
        "    rewards = torch.from_numpy(np.vstack([e.rewards for e in experiences if e is not None])).float().to(device)\n",
        "    next_state = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
        "    done = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None])).float().to(device)\n",
        "      \n",
        "    return state,actions, rewards, next_state, done\n",
        "  def __len__(self):\n",
        "    \"\"\"\n",
        "    Return the current size of internal memory.\n",
        "    \"\"\"\n",
        "    return len(self.memory)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP62kie9ubf6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d3d37e1a-1370-4986-e6ea-8b543480e17f"
      },
      "source": [
        "##A small guide before diving into Double DQN to see how these functions works\n",
        "\n",
        "import torch\n",
        "\n",
        "t = torch.tensor([[2,1],\n",
        "                  [3,4]])\n",
        "\n",
        "#t = torch.tensor([1,2,3],\n",
        "#                )\n",
        "\n",
        "#torch.gather(t, 1, torch.tensor([[1,0],[1,0]]))\n",
        "\n",
        "print(t.gather(1, torch.tensor([[0],[1]])))\n",
        "\n",
        "\n",
        "print(torch.max(t,1)[0])\n",
        "print(torch.max(t,1)[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2],\n",
            "        [4]])\n",
            "tensor([2, 4])\n",
            "tensor([0, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHLpz6dJ1ExI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Define the Agent\n",
        "\n",
        "class Agent():\n",
        "  '''\n",
        "  Interacts with and learns from the environment.\n",
        "  '''\n",
        "  def __init__(self,state_size,action_size, seed,batch_size= BATCH_SIZE,buffer_size= BUFFER_SIZE,lr=LR , gamma= GAMMA ):\n",
        "    \n",
        "    self.state_size = state_size\n",
        "    self.action_size = action_size\n",
        "    self.buffer_size = buffer_size\n",
        "    self.batch_size = batch_size\n",
        "    self.lr = lr\n",
        "    self.gamma = gamma\n",
        "    \n",
        "    self.seed = random.seed(seed)\n",
        "    \n",
        "    # Q-Network\n",
        "    self.qnetwork_local =  QNetwork(self.state_size, self.action_size, seed).to(device)\n",
        "    self.qnetwork_target = QNetwork(self.state_size , self.action_size, seed).to(device)\n",
        "    self.optimizer = optim.Adam(self.qnetwork_local.parameters(),lr= self.lr)\n",
        "    self.criterion = nn.MSELoss()\n",
        "    \n",
        "    # Replay memory\n",
        "    self.memory = ReplayBuffer(action_size, buffer_size, batch_size, seed)\n",
        "    # Initialize time step (for updating every UPDATE_EVERY steps)\n",
        "    self.t_step = 0\n",
        "  \n",
        "  \n",
        "  def step(self,state,actions,rewards, next_state,done):\n",
        "    self.memory.add(state,actions,rewards, next_state,done)\n",
        "    self.t_step =(self.t_step + 1)% UPDATE_EVERY\n",
        "    ## dont learn whenever 1 batch is added.\n",
        "    ##Rather wait for UPDATE_EVERY batch to be added before we call learn once\n",
        "    if self.t_step==0:\n",
        "      if len(self.memory)> self.batch_size:\n",
        "        experiences = self.memory.sample()\n",
        "        self.learn(experiences, self.gamma)\n",
        "    \n",
        "  def learn(self,experiences, gamma):\n",
        "    \"\"\"\n",
        "    Update value parameters using given batch of experience tuples.\n",
        "    \"\"\"\n",
        "    state, actions, rewards,next_state, done = experiences \n",
        "    #target_q = self.qnetwork_target(next_state).detach()\n",
        "    ##target_values = rewards + gamma*torch.max(target_q, 1)[0].unsqueeze(1)*(1-done)\n",
        "    #current_values= self.qnetwork_local(state).gather(1, actions)\n",
        "    \n",
        "    #Double DQN\n",
        "    \n",
        "    current_values= self.qnetwork_local(state).gather(1, actions)\n",
        "    #print('current_values',current_values.shape)\n",
        "    target_q = self.qnetwork_local(next_state)\n",
        "    #print(target_q.shape)\n",
        "    #target_q = torch.max(target_q, 1)[1].unsqueeze(1) #get the indices same as argmax\n",
        "    target_q = torch.max(target_q, 1)[1].unsqueeze(1)\n",
        "    #print('actions',actions.shape)\n",
        "    #print('target_q',target_q.shape)\n",
        "    #print(target_q.shape)\n",
        "    target_values = rewards + gamma*self.qnetwork_target(next_state).gather(1, target_q)*(1-done)\n",
        "    #print('target_values',target_values.shape)\n",
        "    \n",
        "    \n",
        "    #q_values      = current_model(state)\n",
        "    #q_value       = q_values.gather(1, action.unsqueeze(1)).squeeze(1) \n",
        "    #next_q_values = current_model(next_state)\n",
        "    #next_q_state_values = target_model(next_state) \n",
        "\n",
        "    \n",
        "    #next_q_value = next_q_state_values.gather(1, torch.max(next_q_values, 1)[1].unsqueeze(1)).squeeze(1)\n",
        "    #expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
        "    #loss = (q_value - Variable(expected_q_value.data)).pow(2).mean()\n",
        "    \n",
        "    # Get expected Q values from local model\n",
        "    \n",
        "    ##print(state.shape)\n",
        "    ##print('actions:',actions)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    ##current_value = self.qnetwork_local(states).gather(1,actions)\n",
        "    ##print(current_values.shape)\n",
        "    \n",
        "    \n",
        "    # Compute loss\n",
        "    loss = self.criterion(current_values,target_values)\n",
        "    \n",
        "    ##optimization step\n",
        "    self.optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "    \n",
        "    # ----- Update the target network -----\n",
        "    if self.t_step==0:\n",
        "      ## when it comes here self.t_step will always be 0 anyways. \n",
        "      ## So you may remove this if condition\n",
        "      self.soft_update(self.qnetwork_local, self.qnetwork_target,TAU)\n",
        "    \n",
        "  def soft_update(self, qnetwork_local, qnetwork_target,tau):\n",
        "    '''\n",
        "    Update the target Q Network\n",
        "    '''\n",
        "    for local_parms, target_parms in zip(qnetwork_local.parameters(), qnetwork_target.parameters()):\n",
        "      target_parms.data.copy_(tau*local_parms.data + (1.0 -tau)*target_parms.data)\n",
        "        \n",
        "        \n",
        "  def act(self, state, epsilon =0.0):\n",
        "\n",
        "    \"\"\"\n",
        "    Returns actions for given state as per current policy.\n",
        "    \"\"\"\n",
        "    state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "\n",
        "    self.qnetwork_local.eval()\n",
        "    with torch.no_grad():\n",
        "      actions_values = self.qnetwork_local(state)\n",
        "\n",
        "    ##Back to train mode\n",
        "    self.qnetwork_local.train()\n",
        "\n",
        "    # Epsilon-greedy action selection\n",
        "\n",
        "    if random.random() > epsilon:\n",
        "      return np.argmax(actions_values.cpu().data.numpy())\n",
        "    else:\n",
        "      return np.random.choice(np.arange(self.action_size))\n",
        "      \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4BeNf1adeSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dqn(n_episodes = 2000, max_t = 1000, eps_start = 1.0, eps_end = .01, eps_decay = 0.995, trained_score=200.0):\n",
        "  scores =[]\n",
        "  scores_window = deque(maxlen = 100)\n",
        "  eps = eps_start\n",
        "  \n",
        "  for episode in range(1, n_episodes+1):\n",
        "    state = env.reset()\n",
        "    score = 0\n",
        "    for t in range(max_t):\n",
        "      action = agent.act(state,eps)\n",
        "      next_state , rewards, done, _ = env.step(action)\n",
        "      agent.step(state, action,rewards,next_state ,  done )\n",
        "      state = next_state\n",
        "      score += rewards\n",
        "      if done:\n",
        "        break\n",
        "    scores_window.append(score)\n",
        "    scores.append(score)\n",
        "    eps = max(eps_end, eps*eps_decay)  ## reduce randomness epsilon as we learn\n",
        "    print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_window)), end=\"\")\n",
        "    if episode % 100 == 0:\n",
        "      print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_window)))\n",
        "    ##if np.mean(scores_window)>=200.0:\n",
        "    if np.mean(scores_window)>=trained_score:\n",
        "        print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(episode-100, np.mean(scores_window)))\n",
        "        torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
        "        break\n",
        "  return scores\n",
        "    \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdjdjye7k-WY",
        "colab_type": "code",
        "outputId": "47b80aef-e8b7-4486-a273-7ce50a337d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "env_observation_space = 8\n",
        "env_action_space = 4\n",
        "\n",
        "agent = Agent(env_observation_space ,env_action_space, seed=0 )\n",
        "scores = dqn()\n",
        "# plot the scores\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.plot(np.arange(len(scores)) , scores)\n",
        "\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Scores')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 100\tAverage Score: -168.28\n",
            "Episode 200\tAverage Score: -82.69\n",
            "Episode 300\tAverage Score: -34.63\n",
            "Episode 400\tAverage Score: 17.59\n",
            "Episode 500\tAverage Score: 112.48\n",
            "Episode 600\tAverage Score: 157.79\n",
            "Episode 700\tAverage Score: 157.48\n",
            "Episode 797\tAverage Score: 200.37\n",
            "Environment solved in 697 episodes!\tAverage Score: 200.37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEKCAYAAAA8QgPpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-BIPRRL1fBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fComFphRnQ-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the weights from file\n",
        "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
        "\n",
        "for i in range(3):\n",
        "    state = env.reset()\n",
        "    img = plt.imshow(env.render(mode='rgb_array'))\n",
        "    for j in range(200):\n",
        "        action = agent.act(state)\n",
        "        img.set_data(env.render(mode='rgb_array')) \n",
        "        plt.axis('off')\n",
        "        display.display(plt.gcf())\n",
        "        display.clear_output(wait=True)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        if done:\n",
        "            break \n",
        "            \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN7Y4UF9zP7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn4r-0UO3-vw",
        "colab_type": "text"
      },
      "source": [
        "CartPole-v0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYwjanys2Vsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env_id = \"CartPole-v0\"\n",
        "env = gym.make(env_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqoW8lPZ4FKu",
        "colab_type": "code",
        "outputId": "6f86167d-488f-4dac-d718-23d0312592c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "env.observation_space.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn9ws_Jq4F-d",
        "colab_type": "code",
        "outputId": "2559051a-d3f8-4118-cb66-dd3fa0bbac46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "env.action_space.n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr2KEecB4Kmf",
        "colab_type": "code",
        "outputId": "41806f6d-46c9-40da-eaaa-d4edc38e2353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "agent = Agent(env.observation_space.shape[0] ,env.action_space.n, seed=0 )\n",
        "scores = dqn(n_episodes = 2000, max_t = 1000, eps_start = 1.0, eps_end = .01, eps_decay = 0.995, trained_score=170.0)\n",
        "# plot the scores\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.plot(np.arange(len(scores)) , scores)\n",
        "\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Scores')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 100\tAverage Score: 16.94\n",
            "Episode 200\tAverage Score: 12.58\n",
            "Episode 300\tAverage Score: 11.31\n",
            "Episode 400\tAverage Score: 10.57\n",
            "Episode 500\tAverage Score: 9.82\n",
            "Episode 600\tAverage Score: 10.43\n",
            "Episode 700\tAverage Score: 11.84\n",
            "Episode 800\tAverage Score: 79.15\n",
            "Episode 900\tAverage Score: 165.73\n",
            "Episode 943\tAverage Score: 170.10\n",
            "Environment solved in 843 episodes!\tAverage Score: 170.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nHoYvMG4o9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Environment states reshaped"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hyYQgaA9Aa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from collections import deque\n",
        "import gym\n",
        "from gym import spaces\n",
        "import cv2\n",
        "cv2.ocl.setUseOpenCL(False)\n",
        "\n",
        "class NoopResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env, noop_max=30):\n",
        "        \"\"\"Sample initial states by taking random number of no-ops on reset.\n",
        "        No-op is assumed to be action 0.\n",
        "        \"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self.noop_max = noop_max\n",
        "        self.override_num_noops = None\n",
        "        self.noop_action = 0\n",
        "        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n",
        "        self.env.reset(**kwargs)\n",
        "        if self.override_num_noops is not None:\n",
        "            noops = self.override_num_noops\n",
        "        else:\n",
        "            noops = self.unwrapped.np_random.randint(1, self.noop_max + 1) #pylint: disable=E1101\n",
        "        assert noops > 0\n",
        "        obs = None\n",
        "        for _ in range(noops):\n",
        "            obs, _, done, _ = self.env.step(self.noop_action)\n",
        "            if done:\n",
        "                obs = self.env.reset(**kwargs)\n",
        "        return obs\n",
        "\n",
        "    def step(self, ac):\n",
        "        return self.env.step(ac)\n",
        "\n",
        "class FireResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"Take action on reset for environments that are fixed until firing.\"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
        "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        self.env.reset(**kwargs)\n",
        "        obs, _, done, _ = self.env.step(1)\n",
        "        if done:\n",
        "            self.env.reset(**kwargs)\n",
        "        obs, _, done, _ = self.env.step(2)\n",
        "        if done:\n",
        "            self.env.reset(**kwargs)\n",
        "        return obs\n",
        "\n",
        "    def step(self, ac):\n",
        "        return self.env.step(ac)\n",
        "\n",
        "class EpisodicLifeEnv(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n",
        "        Done by DeepMind for the DQN and co. since it helps value estimation.\n",
        "        \"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self.lives = 0\n",
        "        self.was_real_done  = True\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, reward, done, info = self.env.step(action)\n",
        "        self.was_real_done = done\n",
        "        # check current lives, make loss of life terminal,\n",
        "        # then update lives to handle bonus lives\n",
        "        lives = self.env.unwrapped.ale.lives()\n",
        "        if lives < self.lives and lives > 0:\n",
        "            # for Qbert sometimes we stay in lives == 0 condtion for a few frames\n",
        "            # so its important to keep lives > 0, so that we only reset once\n",
        "            # the environment advertises done.\n",
        "            done = True\n",
        "        self.lives = lives\n",
        "        return obs, reward, done, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        \"\"\"Reset only when lives are exhausted.\n",
        "        This way all states are still reachable even though lives are episodic,\n",
        "        and the learner need not know about any of this behind-the-scenes.\n",
        "        \"\"\"\n",
        "        if self.was_real_done:\n",
        "            obs = self.env.reset(**kwargs)\n",
        "        else:\n",
        "            # no-op step to advance from terminal/lost life state\n",
        "            obs, _, _, _ = self.env.step(0)\n",
        "        self.lives = self.env.unwrapped.ale.lives()\n",
        "        return obs\n",
        "\n",
        "class MaxAndSkipEnv(gym.Wrapper):\n",
        "    def __init__(self, env, skip=4):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        # most recent raw observations (for max pooling across time steps)\n",
        "        self._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)\n",
        "        self._skip       = skip\n",
        "\n",
        "    def reset(self):\n",
        "        return self.env.reset()\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Repeat action, sum reward, and max over last observations.\"\"\"\n",
        "        total_reward = 0.0\n",
        "        done = None\n",
        "        for i in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            if i == self._skip - 2: self._obs_buffer[0] = obs\n",
        "            if i == self._skip - 1: self._obs_buffer[1] = obs\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        # Note that the observation on the done=True frame\n",
        "        # doesn't matter\n",
        "        max_frame = self._obs_buffer.max(axis=0)\n",
        "\n",
        "        return max_frame, total_reward, done, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        return self.env.reset(**kwargs)\n",
        "\n",
        "class ClipRewardEnv(gym.RewardWrapper):\n",
        "    def __init__(self, env):\n",
        "        gym.RewardWrapper.__init__(self, env)\n",
        "\n",
        "    def reward(self, reward):\n",
        "        \"\"\"Bin reward to {+1, 0, -1} by its sign.\"\"\"\n",
        "        return np.sign(reward)\n",
        "\n",
        "class WarpFrame(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"Warp frames to 84x84 as done in the Nature paper and later work.\"\"\"\n",
        "        gym.ObservationWrapper.__init__(self, env)\n",
        "        self.width = 84\n",
        "        self.height = 84\n",
        "        self.observation_space = spaces.Box(low=0, high=255,\n",
        "            shape=(self.height, self.width, 1), dtype=np.uint8)\n",
        "\n",
        "    def observation(self, frame):\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "        frame = cv2.resize(frame, (self.width, self.height), interpolation=cv2.INTER_AREA)\n",
        "        return frame[:, :, None]\n",
        "\n",
        "class FrameStack(gym.Wrapper):\n",
        "    def __init__(self, env, k):\n",
        "        \"\"\"Stack k last frames.\n",
        "        Returns lazy array, which is much more memory efficient.\n",
        "        See Also\n",
        "        --------\n",
        "        baselines.common.atari_wrappers.LazyFrames\n",
        "        \"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self.k = k\n",
        "        self.frames = deque([], maxlen=k)\n",
        "        shp = env.observation_space.shape\n",
        "        self.observation_space = spaces.Box(low=0, high=255, shape=(shp[0], shp[1], shp[2] * k), dtype=np.uint8)\n",
        "\n",
        "    def reset(self):\n",
        "        ob = self.env.reset()\n",
        "        for _ in range(self.k):\n",
        "            self.frames.append(ob)\n",
        "        return self._get_ob()\n",
        "\n",
        "    def step(self, action):\n",
        "        ob, reward, done, info = self.env.step(action)\n",
        "        self.frames.append(ob)\n",
        "        return self._get_ob(), reward, done, info\n",
        "\n",
        "    def _get_ob(self):\n",
        "        assert len(self.frames) == self.k\n",
        "        return LazyFrames(list(self.frames))\n",
        "\n",
        "class ScaledFloatFrame(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        gym.ObservationWrapper.__init__(self, env)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        # careful! This undoes the memory optimization, use\n",
        "        # with smaller replay buffers only.\n",
        "        return np.array(observation).astype(np.float32) / 255.0\n",
        "\n",
        "class LazyFrames(object):\n",
        "    def __init__(self, frames):\n",
        "        \"\"\"This object ensures that common frames between the observations are only stored once.\n",
        "        It exists purely to optimize memory usage which can be huge for DQN's 1M frames replay\n",
        "        buffers.\n",
        "        This object should only be converted to numpy array before being passed to the model.\n",
        "        You'd not believe how complex the previous solution was.\"\"\"\n",
        "        self._frames = frames\n",
        "        self._out = None\n",
        "\n",
        "    def _force(self):\n",
        "        if self._out is None:\n",
        "            self._out = np.concatenate(self._frames, axis=2)\n",
        "            self._frames = None\n",
        "        return self._out\n",
        "\n",
        "    def __array__(self, dtype=None):\n",
        "        out = self._force()\n",
        "        if dtype is not None:\n",
        "            out = out.astype(dtype)\n",
        "        return out\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._force())\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self._force()[i]\n",
        "\n",
        "def make_atari(env_id):\n",
        "    env = gym.make(env_id)\n",
        "    assert 'NoFrameskip' in env.spec.id\n",
        "    env = NoopResetEnv(env, noop_max=30)\n",
        "    env = MaxAndSkipEnv(env, skip=4)\n",
        "    return env\n",
        "\n",
        "def wrap_deepmind(env, episode_life=True, clip_rewards=True, frame_stack=False, scale=False):\n",
        "    \"\"\"Configure environment for DeepMind-style Atari.\n",
        "    \"\"\"\n",
        "    if episode_life:\n",
        "        env = EpisodicLifeEnv(env)\n",
        "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
        "        env = FireResetEnv(env)\n",
        "    env = WarpFrame(env)\n",
        "    if scale:\n",
        "        env = ScaledFloatFrame(env)\n",
        "    if clip_rewards:\n",
        "        env = ClipRewardEnv(env)\n",
        "    if frame_stack:\n",
        "        env = FrameStack(env, 4)\n",
        "    return env\n",
        "\n",
        "\n",
        "\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    Image shape to num_channels x weight x height\n",
        "    \"\"\"\n",
        "    def __init__(self, env):\n",
        "        super(ImageToPyTorch, self).__init__(env)\n",
        "        old_shape = self.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]), dtype=np.uint8)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.swapaxes(observation, 2, 0)\n",
        "    \n",
        "\n",
        "def wrap_pytorch(env):\n",
        "    return ImageToPyTorch(env)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-snbX5BP9wpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env_id = \"PongNoFrameskip-v4\"\n",
        "env    = make_atari(env_id)\n",
        "env    = wrap_deepmind(env)\n",
        "env    = wrap_pytorch(env)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQJCldB3cq2I",
        "colab_type": "code",
        "outputId": "f5a424ae-fa26-4f70-e77f-b2ba6d8867dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "env.observation_space.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 84, 84)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZlATdlqfu8V",
        "colab_type": "code",
        "outputId": "85811cde-9530-4717-b1a8-87298bc27ad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "env.observation_space.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1FlcRC06xuX",
        "colab_type": "text"
      },
      "source": [
        "I have made some minor changes to deal with the state which is fed into conv Layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCarqeUk90fN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class QNetwork(nn.Module):\n",
        "  \"\"\"Actor (Policy) Model.\"\"\"\n",
        "  def __init__(self, state_size, action_size, seed,):\n",
        "    '''\n",
        "    Initialize Parameters\n",
        "    '''\n",
        "    super(QNetwork, self).__init__()\n",
        "    self.state_size = state_size\n",
        "    self.action_size = action_size\n",
        "    \n",
        "    self.features = nn.Sequential(\n",
        "            nn.Conv2d(self.state_size[0], 32, kernel_size=8, stride =4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride =2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride =1),\n",
        "            nn.ReLU()\n",
        "    )\n",
        "    \n",
        "    self.fc = nn.Sequential(\n",
        "            ##nn.Linear(self.feature_size(), 512),\n",
        "            nn.Linear(3136, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, self.action_size)\n",
        "    )\n",
        "    \n",
        "  \n",
        "  def forward(self, state):\n",
        "    \"\"\"\n",
        "    Build a network that maps state -> action values.\n",
        "    \"\"\"\n",
        "    \n",
        "    #print('$$',state.shape)\n",
        "    x = self.features(state)\n",
        "    x = x.reshape(state.shape[0],-1)\n",
        "    ##print('--',x.shape)\n",
        "    \n",
        "    \n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "  \n",
        "  def feature_size(self):\n",
        "    return self.features(autograd.Variable(torch.zeros(1, *self.state_size))).view(1, -1).size(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnVLIunsq_hA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Define the Replay Buffer ( Deque)\n",
        "\n",
        "class ReplayBuffer:\n",
        "  \"\"\"\n",
        "  Fixed-size buffer to store experience tuples.\n",
        "  \"\"\"\n",
        "  def __init__(self,action_size, buffer_size, batch_size, seed):\n",
        "    self.seed = random.seed(seed)\n",
        "    self.buffer_size = buffer_size\n",
        "    self.batch_size = batch_size\n",
        "    self.action_size = action_size\n",
        "    \n",
        "    \n",
        "    self.experience = namedtuple(\"Experience\", field_names =[\"state\", \"actions\",\"rewards\",\"next_state\", \"done\"])\n",
        "    self.memory = deque(maxlen= buffer_size)\n",
        "    \n",
        "  def add(self, state, action,rewards, next_state, done):\n",
        "    \n",
        "    \n",
        "    \n",
        "    ##print('**',state.shape)\n",
        "    state = np.expand_dims(state, axis=0)\n",
        "    next_state = np.expand_dims(next_state, axis=0)\n",
        "    ##print('**',state.shape)\n",
        "    \n",
        "      \n",
        "    experience = self.experience(state, action,rewards,next_state, done)\n",
        "    ##print('12',experience.state.shape)\n",
        "    self.memory.append(experience)\n",
        "      \n",
        "  def sample(self):\n",
        "    '''\n",
        "    Randomly sample a batch from experience\n",
        "    '''\n",
        "      \n",
        "    experiences = random.sample(self.memory,k = self.batch_size)\n",
        "      \n",
        "    state = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "    actions = torch.from_numpy(np.vstack([e.actions for e in experiences if e is not None])).long().to(device)  ## dont change to float\n",
        "    rewards = torch.from_numpy(np.vstack([e.rewards for e in experiences if e is not None])).float().to(device)\n",
        "    next_state = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
        "    done = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None])).float().to(device)\n",
        "    \n",
        "    #print('34',state.shape)\n",
        "      \n",
        "    return state,actions, rewards, next_state, done\n",
        "  def __len__(self):\n",
        "    \"\"\"\n",
        "    Return the current size of internal memory.\n",
        "    \"\"\"\n",
        "    return len(self.memory)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNIDM9j5p5dD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Define the Agent\n",
        "\n",
        "class Agent():\n",
        "  '''\n",
        "  Interacts with and learns from the environment.\n",
        "  '''\n",
        "  def __init__(self,state_size,action_size, seed,batch_size= BATCH_SIZE,buffer_size= BUFFER_SIZE,lr=LR , gamma= GAMMA ):\n",
        "    \n",
        "    self.state_size = state_size\n",
        "    self.action_size = action_size\n",
        "    self.buffer_size = buffer_size\n",
        "    self.batch_size = batch_size\n",
        "    self.lr = lr\n",
        "    self.gamma = gamma\n",
        "    \n",
        "    self.seed = random.seed(seed)\n",
        "    \n",
        "    # Q-Network\n",
        "    self.qnetwork_local =  QNetwork(self.state_size, self.action_size, seed).to(device)\n",
        "    self.qnetwork_target = QNetwork(self.state_size , self.action_size, seed).to(device)\n",
        "    self.optimizer = optim.Adam(self.qnetwork_local.parameters(),lr= self.lr)\n",
        "    self.criterion = nn.MSELoss()\n",
        "    \n",
        "    # Replay memory\n",
        "    self.memory = ReplayBuffer(action_size, buffer_size, batch_size, seed)\n",
        "    # Initialize time step (for updating every UPDATE_EVERY steps)\n",
        "    self.t_step = 0\n",
        "  \n",
        "  \n",
        "  def step(self,state,actions,rewards, next_state,done):\n",
        "    self.memory.add(state,actions,rewards, next_state,done)\n",
        "    self.t_step =(self.t_step + 1)% UPDATE_EVERY\n",
        "    ## dont learn whenever 1 batch is added.\n",
        "    ##Rather wait for UPDATE_EVERY batch to be added before we call learn once\n",
        "    if self.t_step==0:\n",
        "      if len(self.memory)> self.batch_size:\n",
        "        experiences = self.memory.sample()\n",
        "        self.learn(experiences, self.gamma)\n",
        "    \n",
        "  def learn(self,experiences, gamma):\n",
        "    \"\"\"\n",
        "    Update value parameters using given batch of experience tuples.\n",
        "    \"\"\"\n",
        "    state, actions, rewards,next_state, done = experiences \n",
        "    \n",
        "    ##print(target_q.shape)\n",
        "    \n",
        "    #Double DQN\n",
        "    \n",
        "    current_values= self.qnetwork_local(state).gather(1, actions)\n",
        "    #print('current_values',current_values.shape)\n",
        "    target_q = self.qnetwork_local(next_state)\n",
        "    #print(target_q.shape)\n",
        "    #target_q = torch.max(target_q, 1)[1].unsqueeze(1) #get the indices same as argmax\n",
        "    target_q = torch.max(target_q, 1)[1].unsqueeze(1)\n",
        "    #print('actions',actions.shape)\n",
        "    #print('target_q',target_q.shape)\n",
        "    #print(target_q.shape)\n",
        "    target_values = rewards + gamma*self.qnetwork_target(next_state).gather(1, target_q)*(1-done)\n",
        "    \n",
        "    \n",
        "    # Compute loss\n",
        "    loss = self.criterion(current_values,target_values)\n",
        "    \n",
        "    ##optimization step\n",
        "    self.optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "    \n",
        "    # ----- Update the target network -----\n",
        "    if self.t_step==0:\n",
        "      ## when it comes here self.t_step will always be 0 anyways. \n",
        "      ## So you may remove this if condition\n",
        "      self.soft_update(self.qnetwork_local, self.qnetwork_target,TAU)\n",
        "    \n",
        "  def soft_update(self, qnetwork_local, qnetwork_target,tau):\n",
        "    '''\n",
        "    Update the target Q Network\n",
        "    '''\n",
        "    for local_parms, target_parms in zip(qnetwork_local.parameters(), qnetwork_target.parameters()):\n",
        "      target_parms.data.copy_(tau*local_parms.data + (1.0 -tau)*target_parms.data)\n",
        "        \n",
        "        \n",
        "  def act(self, state, epsilon =0.0):\n",
        "\n",
        "    \"\"\"\n",
        "    Returns actions for given state as per current policy.\n",
        "    \"\"\"\n",
        "    state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "\n",
        "    self.qnetwork_local.eval()\n",
        "    with torch.no_grad():\n",
        "      actions_values = self.qnetwork_local(state.to(device))\n",
        "\n",
        "    ##Back to train mode\n",
        "    self.qnetwork_local.train()\n",
        "\n",
        "    # Epsilon-greedy action selection\n",
        "\n",
        "    if random.random() > epsilon:\n",
        "      return np.argmax(actions_values.cpu().data.numpy())\n",
        "    else:\n",
        "      return np.random.choice(np.arange(self.action_size))\n",
        "      \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y--K3prBAWf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAI3vecmgRIE",
        "colab_type": "code",
        "outputId": "5d427311-8cfa-43cd-cb7c-7ba6d18f7d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import torch.autograd as autograd \n",
        "\n",
        "agent = Agent(env.observation_space.shape ,env.action_space.n, seed=0 )\n",
        "\n",
        "scores = dqn(n_episodes = 1400000, max_t = 1000, eps_start = 1.0, eps_end = .01, eps_decay = 0.995, trained_score=15.0)\n",
        "# plot the scores\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.plot(np.arange(len(scores)) , scores)\n",
        "\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Scores')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 100\tAverage Score: -16.25\n",
            "Episode 200\tAverage Score: -18.67\n",
            "Episode 214\tAverage Score: -18.42"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQp7RQok5-2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aZv2m96g0tW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}